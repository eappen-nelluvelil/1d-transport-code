{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmsh\n",
    "import math\n",
    "import sys\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pentagon(radius=1.0, clf=0.8, visualize=True):\n",
    "    gmsh.initialize()\n",
    "\n",
    "    # Create a new model\n",
    "    gmsh.model.add(\"pentagon\")\n",
    "\n",
    "    # Define pentagon vertices (centered at origin)\n",
    "    num_sides = 5\n",
    "    angle_inc = 2 * np.pi/num_sides\n",
    "    points = [gmsh.model.geo.addPoint(radius * np.cos(i * angle_inc),\n",
    "                                      radius * np.sin(i * angle_inc), 0.0, 1.0) \\\n",
    "                                        for i in np.arange(num_sides)]\n",
    "    \n",
    "    # Create pentagon by adding lines between consecutive vertices\n",
    "    lines = [gmsh.model.geo.addLine(points[i], points[(i + 1) % num_sides]) \\\n",
    "             for i in np.arange(num_sides)]\n",
    "    \n",
    "    \n",
    "    # Create a curve loop and a plane surface \n",
    "    gmsh.model.geo.addPlaneSurface([gmsh.model.geo.addCurveLoop(lines)])\n",
    "\n",
    "    # Synchronize the internal CAD representation with the Gmsh model\n",
    "    gmsh.model.geo.synchronize()\n",
    "\n",
    "    # Control the mesh resolution by setting the target characteristic length\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthFactor\", clf)\n",
    "\n",
    "    # Generate the 2D mesh\n",
    "    gmsh.model.mesh.generate(2) # 2 corresponds to triangular elements\n",
    "\n",
    "    # Save the mesh to a file\n",
    "    gmsh.write(\"reg_pentagon.msh\")\n",
    "\n",
    "    # Visualize the mesh\n",
    "    if visualize and (\"-nopopup\" not in sys.argv):\n",
    "        gmsh.fltk.run()\n",
    "\n",
    "    # Finalize the gmsh sessions\n",
    "    gmsh.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pentagon triangulation\n",
    "radius = 1.0\n",
    "clf = 1.0\n",
    "visualize = True\n",
    "\n",
    "create_pentagon(radius, clf, visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triangles: [[ 2  6 12]\n",
      " [ 2  7 12]\n",
      " [11 12 13]\n",
      " [ 9 13 15]\n",
      " [ 9 13 16]\n",
      " [ 1 10 14]\n",
      " [ 1  6 14]\n",
      " [11 13 16]\n",
      " [12 13 14]\n",
      " [ 3  7 11]\n",
      " [ 3  8 11]\n",
      " [ 5  9 15]\n",
      " [ 4  9 16]\n",
      " [13 14 15]\n",
      " [ 7 11 12]\n",
      " [ 8 11 16]\n",
      " [ 6 12 14]\n",
      " [10 14 15]\n",
      " [ 5 10 15]\n",
      " [ 4  8 16]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize gmsh\n",
    "gmsh.initialize()\n",
    "\n",
    "# Open mesh file\n",
    "gmsh.open(\"reg_pentagon.msh\")\n",
    "\n",
    "# Extract node data\n",
    "# node_tags: list of node IDs (integers)\n",
    "# node_coords: list of node coordinates (flattened list: x1, y1, z1, x2, y2, z2, ...)\n",
    "node_tags, node_coords, _ = gmsh.model.mesh.getNodes()\n",
    "\n",
    "# Extract elements (triangular elements)\n",
    "# element_types: list of element types (e.g., 2 is for lines, 3 is for triangles)\n",
    "# element_tags: list of element IDs (integers)\n",
    "# element_node_tags: connectivity of nodes for each element (flattened list)\n",
    "elem_types, _, elem_node_tags = gmsh.model.mesh.getElements(2)\n",
    "\n",
    "# Use only x, y coordinates for each node since all z coordinates are 0\n",
    "node_coords = np.array(node_coords).reshape(-1, 3)[:, :2]  \n",
    "node_tags   = np.array(node_tags)\n",
    "\n",
    "# Map node tags to corresponding coordinates\n",
    "node_coords_dict = {tag: coord for tag, coord in zip(node_tags, node_coords)}\n",
    "\n",
    "# print(f\"Node coordinates: {node_coords}, shape: {node_coords.shape}\")\n",
    "# print(f\"Node tags: {node_tags}, shape: {node_tags.shape}\")\n",
    "# print(f\"Node tag to coordinates dictionary: {node_coords_dict}\")\n",
    "\n",
    "# print(f\"Element node tags: {elem_node_tags}\")\n",
    "# print(f\"Element types: {elem_types}\")\n",
    "# Flattened array of node tags that make up each triangular element\n",
    "# Each consecutive list of 3 node tags correspond to a unique triangular element\n",
    "tri_elements = np.array(elem_node_tags[0])\n",
    "\n",
    "# print(f\"Triangular elements: {tri_elements}\")\n",
    "# Reshape nodes to element mapping so that each row \n",
    "# corresponds to a different element\n",
    "# Sort element nodes for faster comparisons when determining neighbors\n",
    "# by checking for shared edges\n",
    "triangles = np.sort(tri_elements.reshape(-1, 3)) \n",
    "print(f\"Triangles: {triangles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute outward facing normal given an edge of an element,\n",
    "# represented by the node coords. of the nodes that make up the edge,\n",
    "# and centroid of element\n",
    "def compute_outward_normal(p1, p2, centroid):\n",
    "    edge_vec = p2 - p1\n",
    "    normal = np.array([-edge_vec[1], edge_vec[0]]) # By construction, normal to edge\n",
    "    normal /= np.linalg.norm(normal)\n",
    "    edge_midpoint = (p1 + p2) / 2.0 \n",
    "    centroid_vec  = edge_midpoint - centroid\n",
    "    # If dot product is negative, negate the normal\n",
    "    # as it points inward relative to edge\n",
    "    if np.dot(normal, centroid_vec) < 0:\n",
    "        normal = -normal\n",
    "    return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute centroid for each element\n",
    "# Centroid = (1/3) * (p1 + p2 + p3), where p_i is node i's coordinate\n",
    "triangle_centroids = np.mean(np.array([[node_coords_dict[node] for node in tri] \\\n",
    "                                      for tri in triangles]), axis=1)\n",
    "# print(f\"Triangle centroids: {triangle_centroids}, shape: {triangle_centroids.shape}\")\n",
    "\n",
    "# Compute o.w.p. normals for each edge of each element\n",
    "triangle_normals = []\n",
    "\n",
    "for tri, centroid in zip(triangles, triangle_centroids):\n",
    "    p1, p2, p3 = node_coords_dict[tri[0]], node_coords_dict[tri[1]], node_coords_dict[tri[2]]\n",
    "    normals = [\n",
    "        compute_outward_normal(p1, p2, centroid),\n",
    "        compute_outward_normal(p2, p3, centroid),\n",
    "        compute_outward_normal(p3, p1, centroid)\n",
    "    ]\n",
    "    triangle_normals.append(normals)\n",
    "\n",
    "# Tensor of size (n_elements, n_nodes_per_element, n_coords_per_normal)\n",
    "# Last two dimensions are (3, 2) for triangular elements\n",
    "triangle_normals = np.array(triangle_normals)\n",
    "# print(f\"Triangle normals: {triangle_normals}, shape: {triangle_normals.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create discrete unit direction vectors\n",
    "n_dirs = 6 # Even # of directions to avoid pure vertical directoins\n",
    "thetas = np.linspace(0, 2*np.pi, n_dirs, endpoint=False)\n",
    "dir_vecs = np.column_stack((np.cos(thetas), np.sin(thetas))) # Has shape (n_dirs, 2)\n",
    "# print(f\"Direction vectors: {dir_vecs}, shape: {dir_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([np.int64(10), np.int64(19)])\n",
      "{np.int64(0): [1], np.int64(1): [14], np.int64(2): [7, 14], np.int64(3): [4], np.int64(4): [7, 12], np.int64(5): [6, 17], np.int64(6): [16], np.int64(7): [15], np.int64(8): [2], np.int64(9): [10], np.int64(10): [], np.int64(11): [3], np.int64(12): [19], np.int64(13): [3, 8], np.int64(14): [9], np.int64(15): [10, 19], np.int64(16): [0, 8], np.int64(17): [13], np.int64(18): [11, 17], np.int64(19): []}\n",
      "Solve order for direction 0: [np.int64(10), np.int64(19)]\n",
      "Task directed graph edges: [10, 19, 9, 15, 12, 14, 7, 1, 2, 4, 0, 8, 3, 16, 13, 11, 6, 17, 5, 18]\n",
      "deque([np.int64(11), np.int64(12)])\n",
      "{np.int64(0): [1, 16], np.int64(1): [14], np.int64(2): [7], np.int64(3): [4, 11], np.int64(4): [12], np.int64(5): [17], np.int64(6): [5, 16], np.int64(7): [4, 15], np.int64(8): [2, 13], np.int64(9): [10], np.int64(10): [15], np.int64(11): [], np.int64(12): [], np.int64(13): [3], np.int64(14): [2, 9], np.int64(15): [19], np.int64(16): [8], np.int64(17): [13, 18], np.int64(18): [11], np.int64(19): [12]}\n",
      "Solve order for direction 1: [np.int64(11), np.int64(12)]\n",
      "Task directed graph edges: [11, 12, 18, 4, 19, 3, 15, 13, 10, 7, 17, 9, 2, 5, 14, 8, 1, 16, 0, 6]\n",
      "deque([np.int64(5), np.int64(18)])\n",
      "{np.int64(0): [16], np.int64(1): [0, 14], np.int64(2): [7, 8], np.int64(3): [11], np.int64(4): [3], np.int64(5): [], np.int64(6): [5], np.int64(7): [4], np.int64(8): [13], np.int64(9): [10, 14], np.int64(10): [15], np.int64(11): [18], np.int64(12): [4], np.int64(13): [3, 17], np.int64(14): [2], np.int64(15): [7, 19], np.int64(16): [6, 8], np.int64(17): [5, 18], np.int64(18): [], np.int64(19): [12]}\n",
      "Solve order for direction 2: [np.int64(5), np.int64(18)]\n",
      "Task directed graph edges: [5, 18, 6, 17, 11, 3, 4, 13, 7, 12, 8, 19, 2, 16, 15, 14, 0, 10, 1, 9]\n",
      "deque([np.int64(5), np.int64(18)])\n",
      "{np.int64(0): [16], np.int64(1): [0], np.int64(2): [8], np.int64(3): [11, 13], np.int64(4): [3], np.int64(5): [], np.int64(6): [5], np.int64(7): [2, 4], np.int64(8): [13, 16], np.int64(9): [14], np.int64(10): [9, 15], np.int64(11): [18], np.int64(12): [4], np.int64(13): [17], np.int64(14): [1, 2], np.int64(15): [7], np.int64(16): [6], np.int64(17): [5, 18], np.int64(18): [], np.int64(19): [12, 15]}\n",
      "Solve order for direction 3: [np.int64(5), np.int64(18)]\n",
      "Task directed graph edges: [5, 18, 6, 17, 11, 16, 13, 0, 8, 3, 1, 2, 4, 14, 7, 12, 9, 15, 10, 19]\n",
      "deque([np.int64(0), np.int64(6)])\n",
      "{np.int64(0): [], np.int64(1): [0], np.int64(2): [8, 14], np.int64(3): [13], np.int64(4): [3, 7], np.int64(5): [6], np.int64(6): [], np.int64(7): [2], np.int64(8): [16], np.int64(9): [14], np.int64(10): [9], np.int64(11): [3, 18], np.int64(12): [4, 19], np.int64(13): [8, 17], np.int64(14): [1], np.int64(15): [7, 10], np.int64(16): [0, 6], np.int64(17): [5], np.int64(18): [17], np.int64(19): [15]}\n",
      "Solve order for direction 4: [np.int64(0), np.int64(6)]\n",
      "Task directed graph edges: [0, 6, 1, 16, 5, 14, 8, 17, 9, 2, 13, 18, 10, 7, 3, 15, 4, 11, 19, 12]\n",
      "deque([np.int64(1), np.int64(9)])\n",
      "{np.int64(0): [1], np.int64(1): [], np.int64(2): [14], np.int64(3): [4, 13], np.int64(4): [7, 12], np.int64(5): [6, 17], np.int64(6): [16], np.int64(7): [2, 15], np.int64(8): [2, 16], np.int64(9): [], np.int64(10): [9], np.int64(11): [3], np.int64(12): [19], np.int64(13): [8], np.int64(14): [1, 9], np.int64(15): [10], np.int64(16): [0], np.int64(17): [13], np.int64(18): [11, 17], np.int64(19): [15]}\n",
      "Solve order for direction 5: [np.int64(1), np.int64(9)]\n",
      "Task directed graph edges: [1, 9, 0, 14, 10, 16, 2, 15, 6, 8, 7, 19, 13, 12, 17, 4, 5, 3, 11, 18]\n"
     ]
    }
   ],
   "source": [
    "# Check if edge of given triangle is a mesh boundary edge\n",
    "def is_boundary_edge(tri, edge_idx):\n",
    "    # If the edge is a boundary edge, then no other element\n",
    "    # will share the edge with the given element\n",
    "    node1, node2 = tri[edge_idx], tri[(edge_idx + 1) % 3]\n",
    "    # Here, np.sum((triangles == node1) | (triangles == node2), axis=1) finds\n",
    "    # the elements whose edges contain either node1 or node2 (as well as both nodes)\n",
    "    # Then, checking for the equality of this sum with 2 finds the number of times\n",
    "    # that the edge composed of node1 and node2 is common to all the elements, \n",
    "    # irrespective of the ordering\n",
    "    edge_occurrences = np.sum((triangles == node1) | (triangles == node2), axis=1) == 2\n",
    "    \n",
    "    # Sum over the edge occurrences \n",
    "    # If the edge is common to only one triangle, then it's a boundary edge\n",
    "    return np.sum(edge_occurrences) == 1\n",
    "\n",
    "def reduce_dependencies(tri_idx, downward_deps_map, deps_per_tri, \\\n",
    "                        solve_buffer, task_graph):\n",
    "    for nbr_idx in downward_deps_map[tri_idx]:\n",
    "\n",
    "        # Add directed edge from the current triangle to the neighboring triangle,\n",
    "        # but do so only if the edge is not already in the task graph\n",
    "        if not task_graph.has_edge(tri_idx, nbr_idx):\n",
    "            task_graph.add_edge(tri_idx, nbr_idx)\n",
    "\n",
    "        # Reduce the number of dependencies of neighboring triangle\n",
    "        # by 1 since one of its edges has received information from the same\n",
    "        # edge of the current triangle\n",
    "        deps_per_tri[nbr_idx] -= 1\n",
    "\n",
    "        # If the neighboring triangle has 0 dependencies, add it to the buffer\n",
    "        # of triangles that are ready to solve\n",
    "        if deps_per_tri[nbr_idx] == 0:\n",
    "            solve_buffer.append(nbr_idx)\n",
    "\n",
    "# Store the task graphs for each direction\n",
    "task_graphs = []\n",
    "\n",
    "# Perform the mesh sweep\n",
    "# Iterate through each direction\n",
    "for i, dir_vec in enumerate(dir_vecs):\n",
    "    # print(f\"Direction {i}, direction vector: {dir_vec}\")\n",
    "\n",
    "    # Each element starts off with 3 dependencies, equal to the number of faces\n",
    "    # of the triangle\n",
    "    deps_per_tri = {tri_idx: 3 for tri_idx in np.arange(len(triangles))}\n",
    "\n",
    "    # Map to store which triangles depend on neighboring triangles for inflow information\n",
    "    downward_deps_map = {i: [] for i in np.arange(len(triangles))}\n",
    "\n",
    "    # Loop over each element and determine the number of dependencies we can reduce:\n",
    "    # (1) if the triangle is a boundary triangle, and has boundary edges that are inflow\n",
    "    #     edges relative to the current direction vector, reduce the number of deps by however\n",
    "    #     many such boundary edges\n",
    "    # (2) for every triangle, if the triangle has outflow edges, reduce the number of deps\n",
    "    #     by however many such edges\n",
    "    for tri_idx, (tri, normals) in enumerate(zip(triangles, triangle_normals)):        \n",
    "        for edge_idx, normal in enumerate(normals):\n",
    "            dp = np.dot(normal, dir_vec)\n",
    "\n",
    "            # If the edge is an outflow edge, # reduce the number of dependencies by 1\n",
    "            if dp >= 0.0:\n",
    "                deps_per_tri[tri_idx] -= 1\n",
    "\n",
    "            # If the edge is a boundary edge, and is an inflow edge relative\n",
    "            # to the direction vector, the boundary element's number of \n",
    "            # dependencies is reduced by 1 because we impose BCs on boundary\n",
    "            # edges\n",
    "            if is_boundary_edge(tri, edge_idx):\n",
    "                if dp < 0.0:\n",
    "                    deps_per_tri[tri_idx] -= 1\n",
    "\n",
    "    # Initialize a task-directed graph (or DAG) to determine the order\n",
    "    # in which we should solve over the triangles, for the current direction,\n",
    "    # using the flow of information in and out of the edges\n",
    "    task_graph = nx.DiGraph()\n",
    "\n",
    "    # Add dependencies from a triangle's outflow edges to its neighboring triangles'\n",
    "    # inflow edges\n",
    "    for tri_idx, (tri, normals) in enumerate(zip(triangles, triangle_normals)):\n",
    "        for edge_idx, normal in enumerate(normals):\n",
    "            # Sort for proper comparison\n",
    "            node1, node2 = tri[edge_idx], tri[(edge_idx + 1) % 3]\n",
    "            sorted_edge = tuple(np.sort([node1, node2])) \n",
    "\n",
    "            # Find neighboring triangles sharing this edge\n",
    "            # Since the element's nodes are sorted, we compare the edge\n",
    "            # to pairs of sorted nodes\n",
    "            nbr_idxs = [\n",
    "                nbr_idx for nbr_idx, nbr_tri in enumerate(triangles) \\\n",
    "                if sorted_edge in [(nbr_tri[0], nbr_tri[1]), (nbr_tri[1], nbr_tri[2]), \\\n",
    "                                      (nbr_tri[0], nbr_tri[2])]\n",
    "            ]\n",
    "\n",
    "            for nbr_idx in nbr_idxs:\n",
    "                if nbr_idx != tri_idx: # Avoid self-loops in task graph\n",
    "                    dp = np.dot(normal, dir_vec)\n",
    "                    # Check if the current edge of the current triangle is an outflow\n",
    "                    # edge, then the same edge for neighboring triangles is an inflow edge\n",
    "                    if dp >= 0.0: # Check for outflow edge\n",
    "                        task_graph.add_edge(tri_idx, nbr_idx)\n",
    "                        downward_deps_map[nbr_idx].append(tri_idx)\n",
    "\n",
    "    # Buffer of triangles that are ready to solve, i.e., triangles that have zero dependencies\n",
    "    solve_buffer = deque([tri_idx for tri_idx, deps in deps_per_tri.items() if deps == 0])\n",
    "\n",
    "    print(solve_buffer)\n",
    "    print(downward_deps_map)\n",
    "\n",
    "    # Determine solve order of the triangles for the current direction\n",
    "    solve_order = []\n",
    "\n",
    "    while solve_buffer:\n",
    "        # Pop the next triangle that is ready to solve (has zero dependencies)\n",
    "        tri_idx = solve_buffer.popleft()\n",
    "        solve_order.append(tri_idx)\n",
    "        reduce_dependencies(tri_idx, downward_deps_map, deps_per_tri, \\\n",
    "                            solve_buffer, task_graph)\n",
    "\n",
    "    print(f\"Solve order for direction {i}: {solve_order}\")\n",
    "    print(f\"Task directed graph edges: {list(nx.topological_sort(task_graph))}\")\n",
    "\n",
    "    task_graphs.append(task_graph)\n",
    "\n",
    "    # if nx.is_directed_acyclic_graph(task_graph):\n",
    "    #     print(\"The graph is a DAG.\")\n",
    "    # else:\n",
    "    #     print(\"NOT A DAG\")\n",
    "\n",
    "    # # Perform a topological sort on the task graph\n",
    "    # top_order = list(nx.topological_sort(task_graph))\n",
    "    # edges_list = list(task_graph.edges())\n",
    "\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # # Draw nodes, edges, and labels\n",
    "    # pos = nx.spring_layout(task_graph)\n",
    "    # nx.draw(task_graph, pos, with_labels=True, node_color=\"lightblue\", \\\n",
    "    #         arrows=True, node_size=500, font_size=10, font_weight=\"bold\")\n",
    "    \n",
    "    # # Draw edge labels to show deps.\n",
    "    # edge_labels = {(u, v): f'{u} -> {v}' for u,v in edges_list}\n",
    "    # nx.draw_networkx_edge_labels(task_graph, pos, edge_labels=edge_labels, font_color='red', font_size=5)\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
